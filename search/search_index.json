{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83d\udcca Welcome to Loyalytics Documentation","text":"<p>Loyalytics is a marketing analytics platform developed for a supermarket chain's Bonus Card Loyalty Program. The project addresses declining sales by analyzing customer behavior, segmenting loyalty profiles, and enabling data-driven decision-making.</p>"},{"location":"#problem","title":"\ud83e\udde0 Problem","text":"<p>Despite having a bonus card program, the supermarket has experienced declining sales. The challenge is identifying:</p> <p>\"What factors are contributing to the drop in sales among bonus cardholders, and how can segmentation improve retention?\"</p>"},{"location":"#solution","title":"\u2705 Solution","text":"<p>We implemented an end-to-end analytics platform that:</p> <ul> <li>Extracts, cleans, and loads transactional and customer data (ETL).</li> <li>Builds a star schema database to support analytical workloads.</li> <li>Performs RFM segmentation and survival analysis on customer data.</li> <li>Visualizes insights via a Streamlit dashboard.</li> <li>Deploys services using Docker Compose for full-stack orchestration.</li> </ul>"},{"location":"#expected-outcomes","title":"\ud83c\udfaf Expected Outcomes","text":"<ul> <li>Clear understanding of customer loyalty patterns.</li> <li>Identification of high-value vs. at-risk segments.</li> <li>Actionable insights through survival modeling and segment summaries.</li> <li>A fully reproducible and documented system accessible via:</li> <li>Streamlit UI: <code>localhost:8501</code></li> <li>FastAPI Docs: <code>localhost:8008/docs</code></li> <li>PgAdmin UI: <code>localhost:5050</code></li> <li>GitHub Pages: https://ds-223.github.io/Group-5/</li> </ul>"},{"location":"#documentation-map","title":"\ud83d\udcc1 Documentation Map","text":"<ul> <li><code>api.md</code> \u2013 RESTful API endpoints for predictions and search</li> <li><code>app.md</code> - StreamLit, Visualizations, and Email Campaign</li> <li><code>database.md</code> \u2013 Database schema, ORM models, and raw table loading</li> <li><code>model.md</code> \u2013 ML logic, RFM pipeline, and survival analysis</li> </ul>"},{"location":"api/","title":"\ud83d\ude80 API Documentation","text":"<p>This service exposes the REST API layer for the Customer Loyalty &amp; Analytics system. It powers the dashboard, segmentation visualizations, survival models, and automated email campaigns.</p> <p>Built with FastAPI, the API provides endpoints for querying customer data, analyzing transactions, generating RFM segments, launching email campaigns, and dashboard filters.</p>"},{"location":"api/#tech-stack","title":"\u2699\ufe0f Tech Stack","text":"<ul> <li>FastAPI \u2013 Lightweight, fast web framework for REST endpoints</li> <li>SQLAlchemy \u2013 ORM for interacting with PostgreSQL</li> <li>Pydantic \u2013 Request validation &amp; API response schemas</li> <li>Lifelines \u2013 Weibull AFT survival analysis</li> <li>BackgroundTasks \u2013 Async email dispatching</li> </ul>"},{"location":"api/#customer-endpoints","title":"\ud83d\udc64 Customer Endpoints","text":"<p>Manage customer profiles stored in <code>DimCustomer</code>:</p> <ul> <li><code>POST /customers/</code> \u2013 Create a new customer  </li> <li><code>GET /customers/{id}</code> \u2013 Retrieve customer details  </li> <li><code>PUT /customers/{id}</code> \u2013 Update customer profile  </li> <li><code>DELETE /customers/{id}</code> \u2013 Remove a customer record  </li> <li><code>GET /analytics/customer-count-by-gender</code> \u2013 Gender-wise customer distribution</li> </ul>"},{"location":"api/#transaction-revenue-analytics","title":"\ud83d\udcb0 Transaction &amp; Revenue Analytics","text":"<p>Explore sales data using joins over the star schema:</p> <ul> <li><code>GET /revenue/monthly</code> \u2013 Monthly revenue totals  </li> <li><code>GET /customers/{id}/transactions</code> \u2013 Full transaction history of a customer  </li> <li><code>GET /analytics/transactions-by-store-month</code> \u2013 Monthly revenue by store  </li> <li><code>GET /analytics/transaction-amount-by-store</code> \u2013 Lifetime revenue by store  </li> </ul>"},{"location":"api/#rfm-segmentation","title":"\ud83d\udcca RFM Segmentation","text":"<p>Provides data on Recency-Frequency-Monetary segments:</p> <ul> <li><code>GET /analytics/customers-by-segment/{segment}</code> \u2013 List of customers in a specific segment  </li> <li><code>GET /analytics/segment-distribution/{all|male|female}</code> \u2013 Distribution of segments overall or by gender  </li> <li><code>GET /analytics/rfm-matrix</code> \u2013 RFM matrix for segment summaries  </li> </ul>"},{"location":"api/#email-campaigns","title":"\ud83d\udce7 Email Campaigns","text":"<p>Launch targeted retention campaigns via segment-specific email templates:</p> <ul> <li><code>GET /analytics/segments_for_button</code> \u2013 List of all segments for frontend dropdowns  </li> <li><code>POST /campaigns/{segment}</code> \u2013 Asynchronously send emails to all users in a segment using BackgroundTasks </li> </ul>"},{"location":"api/#survival-analysis","title":"\ud83d\udcc8 Survival Analysis","text":"<p>Uses Weibull AFT to model customer churn over time:</p> <ul> <li><code>GET /analytics/survival-curve</code> \u2013 Survival probability over time using <code>SurvivalData</code> with Age and Gender as covariates</li> </ul>"},{"location":"api/#scorecard-metrics","title":"\ud83e\uddee Scorecard Metrics","text":"<p>Returns KPIs used for dashboard summary tiles:</p> <ul> <li><code>GET /analytics/summary-scorecards</code> \u2013 Returns revenue, orders, and unique customer count   Filters: <code>store_id</code>, <code>start_date</code>, <code>end_date</code>, <code>segment</code></li> </ul>"},{"location":"api/#dashboard-dropdowns","title":"\ud83e\udde9 Dashboard Dropdowns","text":"<p>Provides values for dynamic filter controls:</p> <ul> <li><code>GET /dropdowns/stores</code> \u2013 List of store IDs and names  </li> <li><code>GET /dropdowns/segments</code> \u2013 All available RFM segments  </li> <li><code>GET /dropdowns/date-range</code> \u2013 Minimum and maximum transaction dates  </li> </ul>"},{"location":"api/#testing","title":"\ud83e\uddea Testing","text":"<p>Test endpoints locally using:</p> <ul> <li>Swagger UI: <code>localhost:8000/docs</code> </li> <li>ReDoc: <code>localhost:8000/redoc</code></li> </ul>"},{"location":"api/#related-files","title":"\ud83d\udcc2 Related Files","text":"File Description <code>main.py</code> FastAPI app with all endpoints <code>schema.py</code> Pydantic models for request/response <code>email_utils.py</code> Email template logic and SMTP sending <code>columns.py</code> SQLAlchemy table mappings <code>Dockerfile</code> FastAPI container setup <code>requirements.txt</code> Python dependencies"},{"location":"api/#status","title":"\u2705 Status","text":"<ul> <li>\ud83d\udcec Email logic verified for all segments  </li> <li>\ud83d\udcc8 Weibull survival curve implemented  </li> <li>\u2705 Swagger-tested endpoints  </li> <li>\ud83d\udc33 Docker Compose ready  </li> </ul> <p>For more information, explore index.md, database.md, app.md and [model.md].</p>"},{"location":"app/","title":"\ud83c\udf9b\ufe0f Streamlit App Documentation","text":"<p>This app is the frontend dashboard for the Loyalytics platform, built using Streamlit. It connects to the REST API to visualize customer loyalty metrics, transactions, revenue trends, RFM segmentation, and survival probabilities.</p>"},{"location":"app/#features-pages","title":"\ud83d\udce6 Features &amp; Pages","text":""},{"location":"app/#dashboard","title":"\ud83e\uddee Dashboard","text":"<ul> <li>Filterable by store, segment, and date range</li> <li>Displays scorecards: Total Revenue, Total Orders, and Total Customers</li> <li>Fetches live data via <code>/dropdowns</code> and <code>/analytics/summary-scorecards</code></li> </ul>"},{"location":"app/#revenue-insights","title":"\ud83d\udcb0 Revenue Insights","text":"<ul> <li>Visualizes monthly revenue using a Plotly bar chart</li> <li>Pulls data from <code>/revenue/monthly</code></li> <li>Cached for fast repeat loads</li> <li>Dark-themed UI with stylish customization</li> </ul>"},{"location":"app/#transaction-analysis","title":"\ud83d\udcb3 Transaction Analysis","text":"<ul> <li>Bar chart: Transaction totals by store (<code>/analytics/transaction-amount-by-store</code>)</li> <li>Line chart: Monthly trends per store (<code>/analytics/transactions-by-store-month</code>)</li> <li>Helps identify store-level purchase behavior</li> </ul>"},{"location":"app/#customer-segmentation","title":"\ud83e\udde0 Customer Segmentation","text":"<ul> <li>Segment distribution bar chart (<code>/analytics/segment-distribution/all</code>)</li> <li>Heatmap from RFM Matrix (<code>/analytics/rfm-matrix</code>)</li> <li>RFM-based campaign launcher with email triggers (<code>/campaigns/{segment}</code>)</li> <li>Dynamic dropdowns from <code>/analytics/segments_for_button</code></li> </ul>"},{"location":"app/#customer-search","title":"\ud83d\udd75\ufe0f\u200d\u2642\ufe0f Customer Search","text":"<ul> <li>Enter a customer ID to view their profile</li> <li>Data pulled via <code>/customers/{id}</code></li> <li>Highlights missing or malformed results</li> </ul>"},{"location":"app/#transaction-search","title":"\ud83d\udcbc Transaction Search","text":"<ul> <li>Enter a customer ID to see all their purchases</li> <li>Data pulled via <code>/customers/{id}/transactions</code></li> </ul>"},{"location":"app/#survival-analysis","title":"\u23f3 Survival Analysis","text":"<ul> <li>Fetches Weibull survival curve (<code>/analytics/survival-curve</code>)</li> <li>Visualizes customer retention over time</li> <li>Shaded 95% confidence intervals</li> </ul>"},{"location":"app/#api-integration","title":"\ud83d\udd10 API Integration","text":"<p>All endpoints are managed through <code>.env</code> file keys:</p> Env Key Description <code>API_REVENUE_ENDPOINT</code> Revenue data <code>API_CUSTOMER_ENDPOINT</code> Customer profile fetch <code>API_TRANSACTIONS_ENDPOINT</code> Customer transactions <code>API_SEGMENTATION_ENDPOINT</code> Segment distribution <code>API_RFM_SEGMENTS_BUTTON</code> Segment dropdowns <code>API_LAUNCH_CAMPAIGN_BASE</code> Launch email campaigns <code>API_TRANSACTIONS_BYSTORE_ENDPOINT</code> Store-level totals <code>API_TRANSACTIONS_MONTH_ENDPOINT</code> Store-level monthly trends <code>API_SEGMENTATION_ENDPOINT_MATRIX</code> RFM matrix <code>API_SURVIVAL_ENDPOINT</code> Survival curve <code>API_STORES_ENDPOINT</code> Store dropdown <code>API_SEGMENTS_ENDPOINT</code> Segment dropdown <code>API_DATERANGE_ENDPOINT</code> Min/Max dates <code>API_SCORECARDS_ENDPOINT</code> Scorecard data"},{"location":"app/#style-theming","title":"\ud83d\udee0\ufe0f Style &amp; Theming","text":"<ul> <li>Full dark mode with consistent typography and layout</li> <li>Responsive sidebar and headers</li> <li>Styled metric boxes and input elements</li> <li>Plotly for all charts</li> <li>Custom CSS blocks embedded per-page</li> </ul>"},{"location":"app/#docker-support","title":"\ud83d\udc33 Docker Support","text":"<p>The app is deployed via Docker. Configuration:</p> <pre><code># Dockerfile snippet\nFROM python:3.10-slim-bullseye\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\nCOPY . .\nEXPOSE 8501\nCMD [\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\", \"--server.headless=true\", \"--server.runOnSave=true\"]\n</code></pre>"},{"location":"app/#requirements","title":"\ud83d\udce6 Requirements","text":"<p>Installed via <code>requirements.txt</code>:</p> <ul> <li><code>streamlit</code>, <code>requests</code>, <code>plotly</code>, <code>dotenv</code>, <code>SQLAlchemy</code>, <code>psycopg2-binary</code></li> <li>Other visualization and dependency libraries (see full file)</li> </ul>"},{"location":"app/#status","title":"\u2705 Status","text":"<ul> <li>\ud83e\uddea Fully tested with API backend</li> <li>\ud83d\udcca Dashboards live and connected</li> <li>\ud83d\udc8c Email integration active</li> <li>\ud83d\udc33 Dockerized and production-ready</li> </ul>"},{"location":"app/#related-files","title":"\ud83d\udcc2 Related Files","text":"File Purpose <code>app.py</code> Streamlit entry point <code>/pages</code> Streamlit web pages <code>.env</code> Stores environment variables <code>Dockerfile</code> Streamlit Docker image <code>requirements.txt</code> Python dependencies"},{"location":"database/","title":"Database Documentation","text":"<p>This service manages the PostgreSQL database for the ETL pipeline and analytics platform. It uses SQLAlchemy ORM to define and interact with the star schema that powers the reporting and machine learning workflows.</p>"},{"location":"database/#star-schema-design","title":"\ud83d\udcd0 Star Schema Design","text":"<p>The schema follows a classic star structure with the following tables:</p> <ul> <li><code>DimDate</code>: Stores date-related attributes.</li> <li><code>DimCustomer</code>: Contains customer metadata (e.g., name, birthdate, gender, email).</li> <li><code>DimStore</code>: Information about store branches including location and size.</li> <li><code>FactTransaction</code>: The central fact table that records every customer transaction.</li> </ul> <p>Each <code>FactTransaction</code> entry references:</p> <ul> <li>a customer (<code>CustomerKey</code> from <code>DimCustomer</code>),</li> <li>a store (<code>StoreKey</code> from <code>DimStore</code>),</li> <li>and a transaction date (<code>DateKey</code> from <code>DimDate</code>).</li> </ul>"},{"location":"database/#orm-models","title":"\u2699\ufe0f ORM Models","text":"<p>The ORM classes in <code>db/star_schema.py</code> define the schema as Python classes.</p> <ul> <li>All models inherit from a common <code>Base</code> defined in <code>db_conf.py</code>.</li> <li>The <code>create_tables()</code> function initializes the schema in the target PostgreSQL database.</li> </ul> <pre><code>Base.metadata.create_all(bind=engine)\n</code></pre>"},{"location":"database/#business-logic-layer","title":"\ud83e\udde0 Business Logic Layer","text":"<p>The class <code>TransactionDatabase</code> in <code>CRUD_func.py</code> wraps direct database interactions such as:</p> <ul> <li>Inserting customers, dates, and transactions</li> <li>Updating or deleting records</li> <li>Fetching data for reporting or debugging</li> </ul>"},{"location":"database/#etl-integration","title":"\ud83d\udd01 ETL Integration","text":"<p>The ETL pipeline loads data into the star schema in multiple phases:</p> <ol> <li>Extract &amp; Load Raw XLSX:</li> <li>Excel files are ingested into raw tables using Pandas and <code>to_sql()</code>.</li> <li> <p>Raw file names are cleaned into table names.</p> </li> <li> <p>Transform:</p> </li> <li>Data is cleaned and standardized (e.g., phone/email formatting, gender unification).</li> <li> <p>Invalid records are dropped.</p> </li> <li> <p>Load to Star Schema:</p> </li> <li>Dimension tables are filled using <code>load_dimcustomer_table()</code> and <code>load_dimdate_table()</code>.</li> <li>Transaction data is processed and inserted using <code>load_facttransaction_table()</code>.</li> </ol>"},{"location":"database/#data-validations","title":"\ud83e\uddea Data Validations","text":"<ul> <li>Dates must follow <code>YYYY-MM-DD</code> and be logically consistent.</li> <li>CustomerCardCodes are filtered to 13-character strings.</li> <li>Phone and address fields are validated for structure and length.</li> <li>Store names are mapped to known clean values using <code>STORE_NAME_MAPPING</code>.</li> </ul>"},{"location":"database/#dependencies","title":"\ud83d\udee0\ufe0f Dependencies","text":"<p>The ETL database logic requires:</p> <ul> <li><code>SQLAlchemy</code></li> <li><code>psycopg2-binary</code></li> <li><code>pandas</code></li> <li><code>loguru</code></li> <li><code>dotenv</code></li> </ul>"},{"location":"database/#configuration","title":"\ud83d\udd10 Configuration","text":"<p>Database credentials are loaded from a <code>.env</code> file:</p> <pre><code>DATABASE_URL=postgresql+psycopg2://postgres:postgres@db:5432/maindb\nDB_USER=postgres\nDB_HOST=postgres-db\nDB_PASSWORD=postgres\nDB_NAME=maindb\nPGADMIN_EMAIL=admin@admin.com \nPGADMIN_PASSWORD=admin\n</code></pre>"},{"location":"database/#related-files","title":"\ud83d\udcc2 Related Files","text":"File Description <code>/db</code> SQLAlchemy Setup: Engine, Base, Session, General Database Configuration <code>CRUD_func.py</code> Class wrapping SQL queries <code>extract_load_raw.py</code> Extracts all XLSX files, does validation and dumps them in the DB <code>transform.py</code> Takes raw tables and does transformation, cleaning and validation <code>load.py</code> Takes clean tables and sequentially loads into DB, row-by-row (FactTransaction, DimCustomer) or by batch <code>main.py</code> Entry point that orchestrates ETL and signals completion"},{"location":"model/","title":"Model Service","text":"<p>The <code>ds</code> service is responsible for performing advanced data analytics, including customer segmentation (via RFM analysis) and customer retention modeling (via survival analysis). It uses preprocessed transaction and customer data from the ETL pipeline and produces insights that are stored in the database and visualized in the frontend.</p>"},{"location":"model/#architecture-overview","title":"\ud83e\uddf1 Architecture Overview","text":"<p>The model pipeline is built with:</p> <ul> <li>SQLAlchemy &amp; pandas: For database interaction and data manipulation</li> <li>scikit-learn: For segmentation (KNN for unknown segment classification)</li> <li>lifelines: For survival analysis (Cox Proportional Hazards, Weibull AFT)</li> <li>matplotlib: For visualization</li> <li>Python + Docker: For containerized execution</li> </ul>"},{"location":"model/#input-output-files","title":"\ud83d\udce6 Input &amp; Output Files","text":"File Path Purpose <code>outputs/customer_transactions.csv</code> Extracted customer transaction data <code>outputs/rfm_results.csv</code> Output of the RFM analysis <code>outputs/survival_data.csv</code> Prepared survival data <code>outputs/*.png</code> Survival plots <code>outputs/*.csv</code> Model summaries"},{"location":"model/#components","title":"\ud83d\udd0d Components","text":""},{"location":"model/#1-data-extraction","title":"1. Data Extraction","text":"<p>Module: <code>db_ops/extract_and_save.py</code></p> <ul> <li><code>extract_transaction_data()</code>: Joins FactTransaction, DimCustomer, and DimDate tables for RFM analysis.</li> <li><code>extract_survival_data()</code>: Constructs a survival dataset with event and duration variables.</li> </ul>"},{"location":"model/#2-rfm-analysis","title":"2. RFM Analysis","text":"<p>Module: <code>utils/rfm_analyzer.py</code></p> <ul> <li><code>calculate_rfm()</code>: Computes recency, frequency, and monetary values per customer.</li> <li><code>score_rfm()</code>: Assigns 1\u20135 scores for each metric.</li> <li><code>segment_customers()</code>: Classifies customers into segments such as:</li> <li>Champions</li> <li>Loyal Customers</li> <li>Potential Loyalists</li> <li>Big Spenders</li> <li>Leaving Customers</li> <li><code>classify_unknown_segments()</code>: Uses KNN classifier to assign a segment to previously unclassified customers.</li> <li><code>analyze_segments()</code>: Produces aggregated statistics per segment.</li> <li><code>save_results()</code>: Saves the detailed results to CSV.</li> </ul>"},{"location":"model/#3-survival-analysis","title":"3. Survival Analysis","text":"<p>Module: <code>utils/survival_analyzer.py</code></p> <ul> <li>Uses <code>lifelines</code> to fit:</li> <li>Cox Proportional Hazards Model</li> <li>Weibull AFT Model</li> <li>Key Methods:</li> <li><code>fit_cox_model()</code></li> <li><code>fit_weibull_model()</code></li> <li><code>print_model_summaries()</code></li> <li><code>save_model_summaries()</code></li> <li><code>plot_weibull_survival_function()</code></li> <li><code>plot_custom_profiles()</code></li> </ul>"},{"location":"model/#output-tables-in-database","title":"\ud83e\uddea Output Tables in Database","text":"Table Description <code>RFMResults</code> RFM scores, segments, and demographic details <code>SurvivalData</code> Raw data used for survival modeling <code>CoxPHSummary</code> Summary of Cox PH model coefficients <code>WeibullAFTSummary</code> Summary of Weibull AFT model coefficients"},{"location":"model/#docker-execution","title":"\ud83d\udc33 Docker Execution","text":"<p>The <code>ds</code> service uses a <code>wait-for-etl.sh</code> script to ensure ETL has completed before running. It then launches:</p> <pre><code>python ds_main.py\n</code></pre> <p>Main entrypoint script: <code>ds_main.py</code>, which calls the full analytics pipeline sequentially.</p>"}]}